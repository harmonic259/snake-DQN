{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T23:23:58.767817Z",
     "start_time": "2023-12-17T23:23:55.215327Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import QNetwork, get_network_input\n",
    "from Game import GameEnvironment\n",
    "from collections import deque\n",
    "from replay_buffer import ReplayMemory\n",
    "import time\n",
    "\n",
    "# TODO: Create an instance for model with input_dim = 10, hidden_dim = 20, output_dim = 5\n",
    "\n",
    "model = QNetwork(10, 20, 5)\n",
    "epsilon = 0.1\n",
    "grid_size = 15 \n",
    "GAMMA = 0.9\n",
    "\n",
    "board = GameEnvironment(grid_size, nothing=0, dead=-1, apple=1)\n",
    "memory = ReplayMemory(1000)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T22:47:27.988868Z",
     "start_time": "2023-12-17T22:47:27.887184Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_episode(num_games):\n",
    "    run = True\n",
    "    games_played = 0\n",
    "    total_reward = 0    \n",
    "    episode_games = 0\n",
    "    snake_len_array = []\n",
    "    \n",
    "    while run:\n",
    "        # TODO: Get state\n",
    "        state = get_network_input(board.snake, board.apple)\n",
    "    \n",
    "        action_0 = model(state)\n",
    "        \n",
    "        # TODO: Compare a random number with epsilon and find out the next action\n",
    "        next_action = torch.argmax(action_0) if np.random.rand() > epsilon else np.random.randint(4)\n",
    "\n",
    "        reward, done, len_of_snake = board.update_board_state(next_action)\n",
    "        \n",
    "        # TODO: Get next state\n",
    "        next_state = get_network_input(board.snake, board.apple)\n",
    "        \n",
    "        memory.push(state, next_action, reward, next_state, done)\n",
    "        \n",
    "        # TODO: update total reward\n",
    "        total_reward += reward\n",
    "        \n",
    "        episode_games += 1\n",
    "        \n",
    "        if board.game_over:\n",
    "            games_played += 1\n",
    "            snake_len_array.append(len_of_snake)\n",
    "            board.reset_game()\n",
    "            \n",
    "            if num_games == games_played:\n",
    "                run = False\n",
    "                \n",
    "    avg_len_of_snake = np.mean(snake_len_array)\n",
    "    max_len_of_snake = np.max(snake_len_array)\n",
    "    return total_reward, avg_len_of_snake, max_len_of_snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T22:47:30.466809Z",
     "start_time": "2023-12-17T22:47:30.364775Z"
    }
   },
   "outputs": [],
   "source": [
    "MSE = nn.MSELoss()\n",
    "def learn(num_updates, batch_size):\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for i in range(num_updates):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sample = memory.sample(batch_size)\n",
    "            \n",
    "        states, actions, rewards, next_states, dones = sample\n",
    "        states = torch.cat([x.unsqueeze(0) for x in states], dim=0) \n",
    "        actions = torch.LongTensor(actions) \n",
    "        rewards = torch.FloatTensor(rewards) \n",
    "        next_states = torch.cat([x.unsqueeze(0) for x in next_states]) \n",
    "        dones = torch.FloatTensor(dones) \n",
    "        \n",
    "        # TODO: Get Q values for current state\n",
    "        q_local = model(states)\n",
    "        \n",
    "        # TODO: Get Q values for next state\n",
    "        next_q_value = model(next_states)\n",
    "\n",
    "        Q_expected  = q_local.gather(1, actions.unsqueeze(0).transpose(0,1)).transpose(0,1).squeeze(0)  \n",
    "        \n",
    "        Q_targets_next = torch.max(next_q_value, 1)[0]*(torch.ones(dones.size()) - dones)\n",
    "        \n",
    "        # TODO: Calculate Q targets for current state\n",
    "        Q_targets  = rewards + GAMMA * Q_targets_next\n",
    "        \n",
    "        loss = MSE(Q_expected, Q_targets)\n",
    "        \n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T23:15:36.671532Z",
     "start_time": "2023-12-17T22:53:57.758768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep.:    100, Loss: 2.426, Avg.Score: -28.00, Avg.LenOfSnake: 5.07, Max.LenOfSnake:  7.00 Time: 00:00:49 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 50\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scores_array, avg_scores_array, avg_len_array, avg_max_len_array    \n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# TODO: Train the model\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m scores, avg_scores, avg_len_of_snake, max_len_of_snake \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 23\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m time_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i_episode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_episodes\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m     21\u001B[0m     \n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# TODO: Run an episode\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m     score, avg_len, max_len \u001B[38;5;241m=\u001B[39m \u001B[43mrun_episode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgames_in_episode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     scores_deque\u001B[38;5;241m.\u001B[39mappend(score)\n\u001B[0;32m     26\u001B[0m     scores_array\u001B[38;5;241m.\u001B[39mappend(score)\n",
      "Cell \u001B[1;32mIn[3], line 12\u001B[0m, in \u001B[0;36mrun_episode\u001B[1;34m(num_games)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m run:\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# TODO: Get state\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     state \u001B[38;5;241m=\u001B[39m get_network_input(board\u001B[38;5;241m.\u001B[39msnake, board\u001B[38;5;241m.\u001B[39mapple)\n\u001B[1;32m---> 12\u001B[0m     action_0 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# TODO: Compare a random number with epsilon and find out the next action\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     next_action \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(action_0) \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrand() \u001B[38;5;241m>\u001B[39m epsilon \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\University\\Term5\\Principles and Aplications of Artificial Intelligence\\project\\project 4\\Bonus-Project\\Student-Version\\model.py:21\u001B[0m, in \u001B[0;36mQNetwork.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     19\u001B[0m l1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(l1)  \u001B[38;5;66;03m# TODO\u001B[39;00m\n\u001B[0;32m     20\u001B[0m l2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(l1))  \u001B[38;5;66;03m# TODO\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m l3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc3\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml2\u001B[49m\u001B[43m)\u001B[49m)  \u001B[38;5;66;03m# TODO\u001B[39;00m\n\u001B[0;32m     22\u001B[0m l4 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc4(l3)  \u001B[38;5;66;03m# TODO\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m l4\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 3000 \n",
    "num_updates = 200 \n",
    "print_every = 100\n",
    "games_in_episode = 30\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_array = []\n",
    "    avg_scores_array = []    \n",
    "    \n",
    "    avg_len_array = []\n",
    "    avg_max_len_array = []\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    \n",
    "    for i_episode in range(num_episodes+1):\n",
    "        \n",
    "        # TODO: Run an episode\n",
    "        score, avg_len, max_len = run_episode(games_in_episode)\n",
    "        \n",
    "        scores_deque.append(score)\n",
    "        scores_array.append(score)\n",
    "        avg_len_array.append(avg_len)\n",
    "        avg_max_len_array.append(max_len)\n",
    "        \n",
    "        avg_score = np.mean(scores_deque)\n",
    "        avg_scores_array.append(avg_score)\n",
    "        \n",
    "        # TODO: Learn from the episode\n",
    "        total_loss = learn(num_updates, batch_size)\n",
    "        \n",
    "        dt = (int)(time.time() - time_start)\n",
    "        \n",
    "        if i_episode % print_every == 0 and i_episode > 0:\n",
    "            print('Ep.: {:6}, Loss: {:.3f}, Avg.Score: {:.2f}, Avg.LenOfSnake: {:.2f}, Max.LenOfSnake:  {:.2f} Time: {:02}:{:02}:{:02} '.\\\n",
    "                  format(i_episode, total_loss, score, avg_len, max_len, dt//3600, dt%3600//60, dt%60))\n",
    "            \n",
    "        memory.truncate()\n",
    "        \n",
    "        if i_episode % 250 == 0 and i_episode > 0:   \n",
    "            torch.save(model.state_dict(), './model/Snake_{}'.format(i_episode))\n",
    "            \n",
    "    return scores_array, avg_scores_array, avg_len_array, avg_max_len_array    \n",
    "\n",
    "# TODO: Train the model\n",
    "scores, avg_scores, avg_len_of_snake, max_len_of_snake = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T23:20:09.052807Z",
     "start_time": "2023-12-17T23:20:08.500986Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('length of scores: ', len(scores), ', len of avg_scores: ', len(avg_scores))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, label=\"Score\")\n",
    "plt.plot(np.arange(1, len(avg_scores)+1), avg_scores, label=\"Avg score on 100 episodes\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1)) \n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episodes #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T23:20:19.810286Z",
     "start_time": "2023-12-17T23:20:19.414789Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1 = fig.add_subplot(121)\n",
    "plt.plot(np.arange(1, len(avg_len_of_snake)+1), avg_len_of_snake, label=\"Avg Len of Snake\")\n",
    "plt.plot(np.arange(1, len(max_len_of_snake)+1), max_len_of_snake, label=\"Max Len of Snake\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1)) \n",
    "plt.ylabel('Length of Snake')\n",
    "plt.xlabel('Episodes #')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}